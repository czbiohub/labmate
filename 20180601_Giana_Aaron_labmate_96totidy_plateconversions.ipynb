{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from functools import reduce \n",
    "\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os.path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that will take in any number of CSVs for metadata for an experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reduce() of empty sequence with no initial value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b5e134941f1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdfs_merged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mdataframes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_plates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/Users/giana.cirolia/Desktop/Nucleofection_Pipelne_Code/experimental_plate_csvs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwell_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"well_id_96\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/Users/giana.cirolia/Desktop/Nucleofection_Pipelne_Code/returned_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"20180529\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mdataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b5e134941f1b>\u001b[0m in \u001b[0;36mmake_metadata\u001b[0;34m(path_to_plates, well_type, path_to_data, date)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtidy_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create list of tidy dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdfs_merged\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwell_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# merge all dataframes together on well_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mdfs_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{a}/{b}_metadata.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reduce() of empty sequence with no initial value"
     ]
    }
   ],
   "source": [
    "def make_metadata(path_to_plates, well_type, path_to_data, date):\n",
    "    ## function that take in formatted csv plates maps from 96 well of 384 well plates and returns metatdata dataframe\n",
    "    ## path_to_plates = absolute path to csvs for your plate layout \n",
    "    ## well_type= well_id_96 or well_id_384\n",
    "    ## date=date of creating metadata \n",
    "    ##import pdb;pdb.set_trace()\n",
    "    all_csv=glob.glob(\"{}/*.csv\".format(path_to_plates)) #import all plate maps \n",
    "    \n",
    "    dict_of_dfs={}\n",
    "\n",
    "    for file in all_csv:\n",
    "        file_name=os.path.splitext(os.path.basename(file))[0] # split based on extension\n",
    "        df=pd.read_csv(file)\n",
    "        dict_of_dfs[file_name]=df\n",
    "    \n",
    "    def remove_cols(df):\n",
    "    ### define a function that will drop unwanted columns from your df along the column axis\n",
    "        cols_to_drop = ['row_letter', 'col_num'] \n",
    "        removed_cols = df.drop(cols_to_drop, axis=1)\n",
    "        return removed_cols\n",
    "\n",
    "    tidy_files={} ## set and empty dictionary to which we will add key value pairs, your file name and the long format of a given 96 well plate\n",
    "    \n",
    "    for file_name, data_frame in dict_of_dfs.items():\n",
    "        df=pd.melt(data_frame, id_vars=\"row_letter\", var_name=\"col_num\", value_name=file_name) # turn 96 well format into long format, returning a df with a list of values for each well in your 96 well plate.  \n",
    "        df[well_type]=df[\"row_letter\"] + df[\"col_num\"] # make a new column to combine row letter with col number. \n",
    "        tidy_files[file_name]= remove_cols(df) # pass the df into the remove cols function to remove col for row letter and col number and add to dictionary with asoociated file name. \n",
    "\n",
    "    dfs=list(tidy_files.values()) # create list of tidy dataframes\n",
    "    dfs_merged=reduce(lambda left,right: pd.merge(left,right, on=well_type), dfs) # merge all dataframes together on well_id\n",
    "    dfs_merged.to_csv(\"{a}/{b}_metadata.csv\".format(a=path_to_data, b=date))\n",
    "    \n",
    "    return dfs_merged\n",
    "\n",
    "dataframes=make_metadata(path_to_plates=\"/Users/giana.cirolia/Desktop/Nucleofection_Pipelne_Code/experimental_plate_csvs\", well_type=\"well_id_96\", path_to_data=\"/Users/giana.cirolia/Desktop/Nucleofection_Pipelne_Code/returned_data\", date=\"20180529\")\n",
    "\n",
    "dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert your work to a python script. \n",
    "\n",
    "`! jupyter nbconvert --to script [yournotebookname].ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 20180601_Giana_Aaron_labmate_96totidy_plateconversions.ipynb to script\n",
      "[NbConvertApp] Writing 2540 bytes to 20180601_Giana_Aaron_labmate_96totidy_plateconversions.py\n"
     ]
    }
   ],
   "source": [
    "! jupyter nbconvert --to script 20180601_Giana_Aaron_labmate_96totidy_plateconversions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
